# Happy Friday!
## Amplify Agency
We're living in an era where AI is reshaping our world faster than we can process. Every day, new tools emerge that can write, analyze, create, and (possibly) even think better than we thought possible just a few short years ago. The buzz is deafening: AI this, agentic that, RAG everything. But beneath the noise, a critical real change is also emerging. Companies are hiring fewer people with expectations to do more. New graduates with software engineering degrees are wondering if they will find a job. Customer support centers are shrinking.

When you see what AI can do, can almost do, and how much effort and investment is going into improving it, a critical question remains: how will we humans thrive in this new landscape?

 

The answer? It turns out agency is all you need. In the AI world, that's about models that can act autonomously. But of course, today I'm writing about human agency. It's the one skill that will keep us ahead of the curve as AI continues to evolve.

 

At its core, having high agency is about taking charge—actively making choices instead of letting circumstances decide for you. It's looking at what's possible, not just what is. It's having a bias for action, a creative mindset that refuses to be hemmed in by problems, and an unshakeable belief that we can influence outcomes. You see it in history's great innovators and leaders—people who changed the world because they believed they could.

 

But it's not just about famous inventors and industry giants. It's about you. It's about me. It's about how we operate day-to-day, how we train our kids to think, and how we prepare ourselves for a future that's going to look very different from today thanks to this incredible technology.

 

## Why High Agency Matters More Than Ever
Right now, AI is taking on more and more tasks that used to be the domain of human beings. Repetitive work, data entry, even decision-making—AI can do it all faster, cheaper, and with fewer errors. But today's AI is still an approximation of true general intelligence. I heard a really great analogy recently about AI being the map while humans live in the territory. For as incredible as the AI is, the words it generates and actions it triggers are based on a single interpretation of our world built up from the data it is trained on. It doesn't experience our problems and connect thoughts across domains in the same way as the human brain. Most importantly it is not reliable enough to be proactive. Most AI Agents have issues with complexity and tasks that stray from their tooling and training.

 

And that's where high agency becomes not just a skill, but a superpower. People with high agency are the ones who find the next opportunities. They'll use AI as a tool to extend their reach and amplify their impact, switching between models and applications as needed. They don't waste time on things that can be done expertly with AI, but they string together AI and other techniques to align to outcomes. Because the truth is, the future is going to reward those who seize opportunities, think outside the box, and adapt quickly.

 

But we have a very big problem. Our post-industrial world doesn't teach this skill naturally. In fact, most organizations are designed to crush it. Our education systems, workplaces, and even societal norms often push us

toward compliance, not creativity; repetition, not innovation. But if we're going to thrive in a world where AI is ubiquitous, we need to change that—starting with ourselves.

 

## Building a High-Agency Mindset
High agency isn't something everyone is born with. It's something you train for, like a muscle that needs regular exercise. I try to challenge myself to strengthen it every day, and I'll be honest—I don't always succeed. There are days when it's easier to let things slide, to just go with the flow and react rather than lead. But I try to push myself to be more intentional, to ask: What can I control today? What steps can I take to move things forward?

 

It's a mindset we need to instill in our children as well. In a world where information is abundant and the tools to work with it are free, children won't need to know the Dewey Decimal system (except as a history lesson). The world of tomorrow will not look like the world of today. Misinformation and deepfakes will be abundant. The jobs our kids will hold likely don't even exist yet. So how do we prepare them for a future we can't predict? By going back to prioritizing critical thinking and recognizing clear thinking. The scientific method which has helped create today's world of abundance must be a part of how we continue to teach and learn. And agency, growth mindset, and related frames of thinking are key to teach children to take ownership of their own learning, to explore new ideas, and to adapt to change.

 

## The Consequences of Staying Passive
Now, let's get real for a moment. For those who don't adopt this mindset, the consequences will be steep. This isn't fear-mongering—this is reality. Look back at the industrial revolution when most farmers had to transition to the city life. A few remained, and adopted mass agriculture or niche farms. Those who couldn't or wouldn't adapt found themselves displaced and struggling. We're seeing the same thing happening now, only now it is primarily impacting those of us who spend our days behind the screen rather than behind the plow.

 

With AI reshaping industries, the rules of the game are changing. Entire job categories are disappearing, while new ones are popping up. If we stay passive, waiting for someone to show us the way, we'll be left behind. But if we take on a high-agency mindset, we can ride this wave, not be drowned by it.

 

## A Call to Action
So, what do we do from here? We work on becoming more agentic every day. We train ourselves to spot opportunities, to take ownership of our decisions, and to act with intention. We learn to harness the incredible innovations and capabilities of AI rather than wait for them to replace us. And we teach our kids to do the same, because they're going to inherit a world where this skill is the difference between flourishing and floundering.

 

We've never had more resources, more knowledge, or more tools at our fingertips than we do right now. But having abundance doesn't guarantee success. Success requires *action*. It requires reaching out, grabbing what's available, and shaping it into something new.

 

As AI continues to evolve, let's make sure we do too—so that we're always the ones steering the ship, not being carried along by the tide.

 

High agency is the future. Let's make it our present.

 

(This essay was co-written with ChatGPT's Advanced Voice mode and a GPT that has samples of my writing style to copy my voice. Even with a solid first draft, I edited it the "old fashioned way" and revised the whole thing.)

 
---

 

## OpenAI Drama

https://arstechnica.com/information-technology/2024/09/openais-murati-shocks-with-sudden-departure-announcement/


OpenAI is undergoing major changes, with the company shifting to a for-profit model and several high-profile executive departures, including CTO Mira Murati and two research leaders. Sam Altman will gain equity for the first time, as the company seeks more investment and ramps up its AI product offerings. Despite the shake-up, OpenAI is still attracting interest from major investors like Microsoft, Apple, and Nvidia, with plans to raise its valuation to $150 billion.

 

## No Drama Llama

https://ai.meta.com/blog/llama-3-2-connect-2024-vision-edge-mobile-devices/


Meta has released Llama 3.2, a new suite of open AI models that includes lightweight text models for edge devices and powerful vision models for advanced image reasoning. This update expands Llama's reach by enabling on-device AI applications and making the models more accessible to developers through partnerships with major players like AWS, Dell, and Qualcomm.

Many companies are looking closely at Llama as a hedge against the uncertainty at OpenAI and some of the other AI labs. Llama's open and on-premises capabilities provide options for security and customizability that can't be matched with a closed approach. While the first wave of AI applications may use APIs, many more will use local models as the drama continues

 

## AI Standards

https://aistandardshub.org/


The AI Standards Hub is a resource designed to support responsible AI development through knowledge sharing and best practices. It's valuable for your audience because it offers a comprehensive catalog of over 300 AI standards, government strategies, and policy documents, all in one place. Users can also stay informed on new and evolving AI standards, access training materials, and participate in community discussions and events. It's ideal for professionals seeking to contribute to AI standardization or stay up-to-date with the latest in AI governance.

 

## AI Alignment Has A Lot to Learn from AI Security; Primarily it is Very Very Hard

https://www.youtube.com/watch?v=umfeF0Dx-r4


Nicholas Carlini, a computer security expert, had a strong message for the AI alignment community: don't repeat the same mistakes the adversarial machine learning crowd made. His warning? It's too easy to make a model look aligned, but incredibly hard to ensure it's truly aligned in all scenarios. He points to adversarial examples in image classification, where tiny changes fool a model into misclassifying an image—despite the image appearing identical to us humans. And after years of research, that problem is still far from solved. Carlini's worry is that without learning from those missteps, AI alignment could end up stuck in the same cycle of patching issues instead of finding true solutions.

 

## Data Poisoning

https://www.crn.com/news/ai/2024/the-ai-danger-zone-data-poisoning-targets-llms


Optiv's own Bill Young is featured in this CRN article, sounding the alarm on a major concern for AI security professionals—data poisoning. He explains that traditional pentesting strategies need to evolve to incorporate the features and peculiarities of large language models (LLMs). This makes securing them much more complex and demands a fresh approach to testing and defense. As the use of generative AI continues to grow, it's crucial that we pay attention to insights like Bill's and adapt our security strategies to keep pace with these new challenges.

 

## AI Forecasting - Better than Humans?

https://www.safe.ai/blog/forecasting


A very interesting demonstration of a way that an AI "expert" can reproduce some of the statistical and reasoning steps of human forecasters. This bot uses GPT-4o to make predictions by analyzing news articles and providing a calibrated probability, all while avoiding the typical biases found in human decision-making. Although it's not perfect, it's a great example of how AI can enhance the forecasting field and offer insights for complex scenarios like elections or geopolitical risks.

 

 

 

# Have a Great Weekend!

![Have a great weekend](./images/ai-says-humans-evil.jpg)



 