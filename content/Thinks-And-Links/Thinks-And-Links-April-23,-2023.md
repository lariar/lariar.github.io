---
title: Thinks And Links April 23, 2023
draft: false
tags:
- Big Data
- Data Analytics
- AI
- Cybersecurity
- Large Language Models
- Ethics in AI
- Future of Work
- NIST
- AI Policy
- RSA Conference
- Penetration Testing
- ChatGPT
- Elasticsearch
- Stack Overflow
- Copyright
- SQL
- AI Innovations
---

# Big Data & Analytics - Thinks & Links | April 23, 2023

![](../images\1679742887729)

#### BD&A - Thinks and Links

Big Data & Analytics - Thinks and Links | News and insights at the intersection of cybersecurity, data, and AI

![](../https://media.licdn.com/mediaD4E12AQGBnWnfGkCp6A)

I spent some time this week in the great state of Michigan speaking to several different groups about AI, ChatGPT, Cyber Security, and a whole host of related topics. Chief Information Security Officers (CISOs) and their teams came out for breakfasts, lunches, and dinners where everyone had questions about AI. The conversations were animated and exciting! We discussed how these new AI models work, what risks they introduce (Cyber and otherwise), and what to do about it. We also touched on fun topics like the future of work, the ethics of AI, and if we’re all living in a simulation.

The conversations were engaging and they were also truly validating that we’re all thinking about the same things. AI - particularly LLM technology - is being figured out as we go, together this year. The increased focus on AI this year is impacting all our businesses.

Here's what we’re hearing from our clients:

What does this mean for you?

---

Former OpenAI Team at Anthropic: Invest in NIST for AI

https://www.anthropic.com/index/an-ai-policy-tool-for-today-ambitiously-invest-in-nist

The National Institute of Standards and Technology (NIST) is working on AI measurement and standards setting efforts, but Anthropic believes increasing funding would be critical to allow for faster and better creation of measures of AI assurance, safety, trust, and innovation. This could lead to a path for system certification that could pair with policy levers for responsible AI.

Headed to RSA Next Week? Check Out This Session on Pen Testing and AI

https://www.darkreading.com/dr-tech/7-sizzling-sessions-check-out-rsa-conference-2023?slide=7

Davi Ottenheimer will be speaking about testing and AI/ML models, including how we need to think not just about how the model can be defeated, but how it is deployed so that some of the obvious exploits are never exposed. Ottenheimer wrote a great article on this last week.

ChatGPT + Elasticsearch

https://www.elastic.co/blog/chatgpt-elasticsearch-openai-meets-private-data

How to use a powerful Chatbot with a powerful search engine

Stack Overflow Would Like to be Paid for Training LLMs

https://www.wired.com/story/stack-overflow-will-charge-ai-giants-for-training-data/

Code creation is arguably one of the most incredible features of LLMs. You type a barely grammatical sentence in and have working code out in seconds. This capability was enabled by OpenAI reading an unknown number of technical data sources – very likely including Stack Overflow. There’s going to be some interesting discussions about ownership and copyright as these sources try to either get paid or be removed from commercially available LLMs. The usage rights of code generated by ChatGPT are also still TBD. AI is many things, but it is most certainly going to be a gold rush for lawyers (and AI bots trained to act as them)

AI has mastered SQL

https://medium.com/querymind/gpt-4s-sql-mastery-2cd1f3dea543

This article walks through the reasoning behind the statement that data base searching via the SQL language is now a solved problem by AI. The article reviews several different operations and logical steps that the AI has to know to handle any SQL query. Perhaps not surprising today – but mind-blowing just a few weeks ago – it scores a 98.9% accuracy in this author’s testing.

Have A Great Weekend!

![No alt text provided for this image](../images\1682242697470)