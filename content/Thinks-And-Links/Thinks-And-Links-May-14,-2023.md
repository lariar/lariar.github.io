---
title: Thinks And Links May 14, 2023
draft: false
tags:
- Big Data
- Data Analytics
- Cybersecurity
- AI
- OpenAI
- Google
- Microsoft
- ChatGPT
- Software Development
- Machine Learning
- Technology News
---

# Big Data & Analytics - Thinks and Links | May 14, 2023

![](../images\1679742887729)

#### BD&A - Thinks and Links

Big Data & Analytics - Thinks and Links | News and insights at the intersection of cybersecurity, data, and AI

![](../https://media.licdn.com/mediaD4E12AQE7GBz1OC7w-w)

Happy Sunday and Mother’s Day!

“AI is helpful for writing emails and building marketing content, but what does it have to do with cybersecurity?”

I’ve heard variations of this statement from clients, colleagues, and family members a lot over the past few months. To answer that question, I’ve started a repository of use cases. It turns out there are a lot of people thinking about how to use AI in cybersecurity and the more we discuss it the more ideas emerge. Perhaps we’ll see products emerge that use the OpenAI APIs to provide some of these functionalities. In other case it’ll be custom trained models which accomplish these tasks. These models can classify, summarize, synthesize, and create. If you provide proper context and have strong systems in place they can augment and accelerate a lot of what humans do today. The degree to which AI can do each of these tasks varies. Accelerating 5% of a task that is repeated hundreds of times can still net major savings. Or providing a quick-start to something that could take hours can boost productivity.

You can find the current latest version here and a snapshot is below. What would you add / change on this list?

![No alt text provided for this image](../images\1684093559780)

And yes, one additional use case not listed above: “Create a mind map listing potential use cases for Large Language Models in Cybersecurity” – the first draft from AI was then modified to include examples and details I’ve heard from clients and colleagues.

---

Google Strikes Back

https://blog.google/technology/ai/google-palm-2-ai-large-language-model/

https://mashable.com/article/google-io-2023-everything-you-need-to-know-ai

Google announced the release of their PaLM 2 model this week, an enhanced version of their LLM technology meant to be competitive with GPT-4. It is immediately available in Bard as well as coming to 24 other products and features. Bard has been released from limited beta and is now widely available. Additional things you can do with AI and Google include: use text generation in Google Documents and Gmail, Conversational Search, Create spreadsheets, edit photos, and create immersive maps experiences.

Microsoft Investing in Builder.AI to Deploy More AI-assisted Development

https://techcrunch.com/2023/05/11/microsoft-makes-strategic-investment-into-builder-ai-integrates-its-services-into-teams

Microsoft has been on a roll with development tools using their purchase of Github in 2018 to form the basis of the autopilot coding tool that has been taking software engineering teams by storm. This new partnership may further democratize the creation of apps with non-technical users. This is both an exciting acceleration of software development capabilities for companies as well as a quickly expanding risk surface for cybersecurity teams.

100,000 is a Lot of Tokens

https://www.anthropic.com/index/100k-context-windows

ChatGPT and GPT-4 are impressive, but if you’ve tested the limits of these tools you’ll discover that longer prompts or chats can lose context over time. Or say you want to load the equivalent of 5 hours worth of reading into a chatbot and have it summarize for you. From the article:

> “we loaded the entire text of The Great Gatsby into Claude-Instant (72K tokens) and modified one line to say Mr. Carraway was “a software engineer that works on machine learning tooling at Anthropic.” When we asked the model to spot what was different, it responded with the correct answer in 22 seconds.”

LinkedIn Live: AI and ChatGPT: The Future is Here, Its Implications Unclear

https://www.linkedin.com/video/live/urn:li:ugcPost:7061760703233155072/

Heather Rim, James Turgal, and I discuss the good, bad, and risky of AI. Common take away from the conversation: don’t fear the technology – embrace it. Understand what it can and can’t do, how to secure it, and how it could cause real harm. But moving confidently in conditions of risk is what we’re here to help our clients and their businesses do.

New Blog Post: Cybersecurity in the AI Era

https://www.optiv.com/insights/discover/blog/cybersecurity-ai-era

AI is getting better, making cybersecurity more important as it gives hackers stronger tools and changes how we see online threats. With AI, hackers can create more realistic fake emails, videos, and voices, which makes it harder to catch them. To keep safe from these threats, organizations need to learn about AI, check their security readiness, include AI in their risk plans, teach employees about AI dangers, and keep watch on how AI is being used.

---

Have a Great Weekend!

![No alt text provided for this image](../images\1684093626032)