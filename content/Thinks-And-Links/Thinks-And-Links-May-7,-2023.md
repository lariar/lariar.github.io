---
title: Thinks And Links May 7, 2023
draft: false
tags:
- Big Data
- Data Analytics
- AI
- Machine Learning
- Cybersecurity
- AI Policy
- AI Ethics
- AI Innovation
- Data Privacy
---

# Big Data & Analytics - Thinks and Links | May 7, 2023

![](../images\1679742887729)

#### BD&A - Thinks and Links

Big Data & Analytics - Thinks and Links | News and insights at the intersection of cybersecurity, data, and AI

![](../https://media.licdn.com/mediaD4E12AQEiCmMJ64Sg-w)

This may be the defining chart of our time:

![No alt text provided for this image](../images\1683457907672)

That’s a picture from 2022 of the pace of research for Machine Learning and Artificial Intelligence in terms of the number of new research papers released each month. (Source) The amount of innovation in the overall Data and AI community right now is astounding. There is a perfect storm of conditions creating a hype cycle that may be larger than the cycles for Cloud, Mobile, or even Internet. Those conditions:

What a time to be alive. Perhaps we’ll look back next year and think of these as the boom times when expectations were high, and hype was overheated. Remember the metaverse? But I don’t think so. The articles I’m seeing and the conversations I’m hearing are telling me the opposite.

We polled the audience in a company-wide meeting about Data and AI at Optiv this week, and there was an even split for how many were excited about AI ~40% and how many think its very risky ~40%. But there was no question that 74% of the people who attended had heard their clients talking about cost pressures driven in part by the conditions above. Everyone has too much data. Everyone needs to cut costs. Everyone is fielding questions from the board about AI and better analytics.

Looking at that chart again I’ve found myself wondering this week: maybe we’re not hyped enough.

---

Shameless Plug - LinkedIn Live on AI This Tuesday

![No alt text provided for this image](../images\1683458217318)

---

Stock Price After AI

![No alt text provided for this image](../images\1683458300643)

https://www.cnbc.com/2023/05/02/chegg-drops-more-than-40percent-after-saying-chatgpt-is-killing-its-business.html

Depending who you ask Chegg either provides homework assistance and online tutoring or is the leading source for cheating on homework and quizes. Regardless – it was doing extremely well until March when “… we saw a significant spike in student interest in ChatGPT. We now believe it’s having an impact on our new customer growth rate.” With these words by CEO on Monday’s earnings call 40% of the company’s valuation vanished. This is one more statistic that boards and CEOs will be thinking about as they contemplate the impact of AI on their stock price. Plan accordingly.

Google’s Concerned and OpenAI Should Be To

https://www.semianalysis.com/p/google-we-have-no-moat-and-neither

This article is not about evil AI. Although Google is also concerned about that. This article is instead about some apparently leaked internal documents from Google about the rise of the Open Source AI ecosystem. TLDR – there are countless powerful AI models that can provide all sorts of economic benefits that do not need to be served by Google (or other AI giants). These models can be trained for small amounts of money and provide similar benefits. And so all of the investment and research to get to this point may end up being far less profitable than Google (and other AI giants) projects. We’re still in the first inning of this hockey game, but for example check out the following references from Google:

AI Goes to Washington

https://www.whitehouse.gov/briefing-room/statements-releases/2023/05/04/fact-sheet-biden-harris-administration-announces-new-actions-to-promote-responsible-ai-innovation-that-protects-americans-rights-and-safety/

CEOs of Alphabet, Anthropic, Microsoft, and OpeanAI gathered on Thursday in Washington with Vice President Harris and senior Administration officials to discuss AI and society. The linked statement includes a list of some of the investments and activities the Administration is taking with respect to AI. This includes more investment into responsible AI research and development, a large-scale penetration test of AI platforms in and around the DEFCON 31 conference, and the release of the Federal Government’s own AI policy guidance for both using and defending AI.

Box AI

https://twitter.com/levie/status/1653620490853044224?s=12&t=Xfz7Jt8IbctmDVkKOxciGw

This is a very cool soon-to-be-released feature of the popular cloud storage platform Box where AI can allow you to talk to your files. If your files are purely public domain examples like the 120 page Fed paper in the link this is awesome! However if you are looking to find new vulnerabilities in locations rich with sensitive data this also looks pretty enticing. Features like this are creeping in to tools everywhere, and it is important that cyber security and risk has a say over when and if they get enabled.

Open Bing AI

https://techcrunch.com/2023/05/04/microsoft-doubles-down-on-ai-with-new-bing-features/

As of yesterday, the AI chat functionality on www.bing.com that uses OpenAI is open to the public. No waitlist or license needed. (You will have to use Microsoft Edge browser though). One feature I really like about Bing’s chatbot is that it shows sources of information used in the response.

![No alt text provided for this image](../images\1683458459671)

Additional new functionality that is available or imminent:

ChatGPT-Detector for Education Falsely Accused Cheating

https://www.washingtonpost.com/technology/2023/04/01/chatgpt-cheating-detection-turnitin/

Detecting AI-written text is hard. Some people write like robots. Some robots write like people. AI detection is not reliable enough.

AI Best Practice: Don’t Use Impersonate an Athlete with AI for a Magazine Cover Article

https://www.espn.com/f1/story/_/id/36235366/michael-schumacher-family-take-legal-action-fake-ai-interview

When Joe Rogan Interviewed Steve Jobs six months ago it was clearly meant as a demonstration of the technology and a fascinating “what if” provided by AI. When Germen magazine Die Aktuelle announced a cover story with an interview with F1 champion Michael Schumacher they neglected to mention that it was via AI since Schumacher has been out of the public eye since a 2013 skiing accident.

Optiv in IT Brew

https://www.itbrew.com/stories/2023/04/28/coders-take-first-crack-at-ai-in-the-enterprise

“One should never be copy-pasting something out of ChatGPT or somewhere else and just running that code in production; that’s just a recipe for disaster,” said Randy Lariar, practice director for big data and analytics at the consultancy Optiv. “But if you’re an experienced developer…you can certainly get a lot of acceleration.”

Unpacking the Hype: Navigating the Complexities of Advanced Data Analytics in Cybersecurity

https://www.youtube.com/watch?v=EZKGLc0eoOY&t=41s

The cybersecurity industry is experiencing an explosion of innovative tools designed to tackle complex security challenges. However, the hype surrounding these tools has outpaced their actual capabilities, leading many teams to struggle with their complexity and struggle to extract value from their investment.

To address these challenges, Cribl's Ed Bailey and Optiv's Randy Lariar will explore the potential and issues of bringing advanced data analytics, including artificial intelligence, to the cybersecurity space. They shared insights on where teams should focus their attention and how to set realistic expectations on what will deliver true value and what may not justify the investment of time and money. It is crucial to have the right people and processes in place to maximize the return on investment from these tools.

---

Have a Great Weekend!

![No alt text provided for this image](../images\1683458511313)